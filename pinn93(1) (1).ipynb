{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Xphil-5B9rkG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import Input, Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FYxJxRfnsyA",
        "outputId": "3d7a9c9a-a88d-47c8-ab6a-18f9a8739d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"u(x, y),v(x,y)\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 50)                250       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 100)               5100      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " Output (Dense)              (None, 2)                 202       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,952\n",
            "Trainable params: 40,952\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model1 = Sequential([\n",
        "    Input(shape=(4,)),\n",
        "    Dense(50, 'tanh'),\n",
        "    Dense(50, 'tanh'),\n",
        "    Dense(50, 'tanh'),\n",
        "    Dense(100, 'tanh'),\n",
        "    Dense(100, 'tanh'),\n",
        "    Dense(100, 'tanh'),\n",
        "    Dense(100, 'tanh'),\n",
        "    Dense(2, 'tanh', name='Output')\n",
        "], name='u(x, y),v(x,y)')\n",
        "\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "YvJgLBIgnvs6"
      },
      "outputs": [],
      "source": [
        "num_points =50\n",
        "x = np.linspace(-1, 1, num_points)\n",
        "y = np.linspace(-1, 1, num_points)\n",
        "fx = np.linspace(0, 2, num_points)\n",
        "fy = np.linspace(0, 2, num_points)\n",
        "\n",
        "grid_x, grid_y,grid_fx,grid_fy = np.meshgrid(x, y,fx,fy)\n",
        "states = np.array(list(zip(grid_x.reshape(-1), grid_y.reshape(-1),grid_fx.reshape(-1),grid_fy.reshape(-1))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "KF52Mr47nxuF"
      },
      "outputs": [],
      "source": [
        "G = tf.cast(tf.constant(1), tf.float32)\n",
        "E = tf.cast(tf.constant(2.6), tf.float32)\n",
        "v = tf.cast(tf.constant(0.3), tf.float32)\n",
        "Lambda = tf.cast(tf.constant(.857142857), tf.float32)\n",
        "\n",
        "\n",
        "#v=0.3,G=1,E=2.6\n",
        "\n",
        "def differential_loss(model, training_dat):\n",
        "\n",
        "    training_data = tf.Variable(tf.cast(training_dat, tf.float32))\n",
        "\n",
        "    tds = training_data.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape_dubgrad:\n",
        "       with tf.GradientTape(persistent=True) as tape_grad:\n",
        "              outputs = model(training_data)\n",
        "\n",
        "              du_dx__du_dy__du_dkx__du_dky = tape_grad.gradient(outputs[:,0], training_data)\n",
        "              dv_dx__dv_dy__dv_dkx__dv_dky = tape_grad.gradient(outputs[:,1], training_data)\n",
        "              D_Du = du_dx__du_dy__du_dkx__du_dky\n",
        "              D_Dv = dv_dx__dv_dy__dv_dkx__dv_dky\n",
        "              du_dx,du_dy,du_dkx,du_dky= D_Du[:,0],D_Du[:,1],D_Du[:,2],D_Du[:,3]\n",
        "              dv_dx,dv_dy,dv_dkx,dv_dky= D_Dv[:,0],D_Dv[:,1],D_Dv[:,2],D_Dv[:,3]\n",
        "\n",
        "              d2u_dy2 = tape_dubgrad.gradient(du_dy, training_data)[:,1]\n",
        "              d2v_dy2 = tape_dubgrad.gradient(dv_dy,training_data)[:,1]\n",
        "\n",
        "              d2u_dx2 = tape_dubgrad.gradient(du_dx, training_data)[:,0]\n",
        "              d2v_dx2 = tape_dubgrad.gradient(dv_dx, training_data)[:,0]\n",
        "\n",
        "\n",
        "              d2v_dxdy = tape_dubgrad.gradient(dv_dy, training_data)[:,0]\n",
        "              del tape_grad\n",
        "       d2u_dxdy = tape_dubgrad.gradient(du_dy, training_data)[:,0]\n",
        "       d2u_dydx = tape_dubgrad.gradient(du_dx, training_data)[:,1]\n",
        "\n",
        "\n",
        "      #  dux_vy_dx = tape_dubgrad.gradient(du_dx + dv_dy,training_data[:,0])\n",
        "      #  dux_vy_dy = tape_dubgrad.gradient(du_dx + dv_dy,training_data[:,1])\n",
        "       dux_vy_dx = d2u_dx2 + d2v_dxdy\n",
        "       dux_vy_dy = d2u_dydx + d2v_dy2\n",
        "    del tape_dubgrad\n",
        "\n",
        "\n",
        "\n",
        "    diff_loss = (G*(d2u_dx2 + d2u_dy2) + (G+Lambda)*(dux_vy_dx) + training_data[:,2])**2 + (G*(d2v_dx2 + d2v_dy2) + (G+Lambda)*(dux_vy_dy) + training_data[:,3])**2\n",
        "    diff_loss = tf.reduce_sum(diff_loss)\n",
        "    return diff_loss\n",
        "\n",
        "\n",
        "def boundary_loss(model,training_dat):\n",
        "\n",
        "\n",
        "    training_data = tf.Variable(tf.cast(training_dat, tf.float32))\n",
        "\n",
        "\n",
        "    states_x_1 = training_data[training_data[:, 0] == -1]\n",
        "    states_y_1 = training_data[training_data[:, 1] == -1]\n",
        "    states_kx0ky0 = training_data[training_data[:, 2]**2 + training_data[:, 3]**2 == 0]\n",
        "\n",
        "    tds = training_data.shape[0]\n",
        "    states_y_1 = tf.Variable(states_y_1)\n",
        "\n",
        "\n",
        "\n",
        "    bound_loss = (model(states_x_1)[:,0])**2 + (model(states_x_1)[:,1])**2\n",
        "\n",
        "\n",
        "    bound_loss = tf.reduce_sum(bound_loss)+ tf.reduce_sum((model(states_kx0ky0)[:,0])**2) + tf.reduce_sum((model(states_kx0ky0)[:,1])**2)\n",
        "    return bound_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "TtAlekrCpqx8"
      },
      "outputs": [],
      "source": [
        "def compute_cost(model, training_data, _lambda=0):\n",
        "    return 100*boundary_loss(model,training_data) + differential_loss(model, training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Gb5Mkdu4pw6K"
      },
      "outputs": [],
      "source": [
        "# print(compute_cost(model1,states))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "5AzpffnIp3Sa"
      },
      "outputs": [],
      "source": [
        "# print(compute_cost(model1,states))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "KENYxub3qNQW"
      },
      "outputs": [],
      "source": [
        "def train_model(model, states, num_epochs=300, lr=0.00001, decay=0.000001, _lambda=0):\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr, weight_decay=decay)\n",
        "    cost_history = []\n",
        "    # initial_lr = 0.00009  # Initial learning rate\n",
        "    # decay_steps = 1000  # Number of steps before decaying the learning rate\n",
        "    # decay_rate = 0.5  # Decay rate for the learning rate\n",
        "\n",
        "    # learning_rate_schedule = tf.keras.optimizers.schedules.ExponentialDecay( initial_learning_rate=initial_lr,decay_steps=decay_steps,decay_rate=decay_rate)\n",
        "\n",
        "    # optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            cost_value = compute_cost(model, states, _lambda=_lambda)\n",
        "\n",
        "        gradients = tape.gradient(cost_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        cost_history.append(cost_value)\n",
        "\n",
        "        print(\"epochs\",epoch)\n",
        "        print(cost_value)\n",
        "        if(cost_value<1e-5):\n",
        "          break\n",
        "\n",
        "    return model, cost_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "x0fkrqMSsy2G",
        "outputId": "daae5c18-c54a-4fc8-d24b-2d8baa97cc71"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-19c9a0322d80>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Behaviour with epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-004648a3cb20>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, states, num_epochs, lr, decay, _lambda)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mcost_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_lambda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-17510a2e5167>\u001b[0m in \u001b[0;36mcompute_cost\u001b[0;34m(model, training_data, _lambda)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mboundary_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdifferential_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-93b1549469c6>\u001b[0m in \u001b[0;36mdifferential_loss\u001b[0;34m(model, training_dat)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape_dubgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersistent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m               \u001b[0mdu_dx__du_dy__du_dkx__du_dky\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7261\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7262\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'dense_14' (type Dense).\n\n{{function_node __wrapped__BiasAdd_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[6250000,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:BiasAdd]\n\nCall arguments received by layer 'dense_14' (type Dense):\n  • inputs=tf.Tensor(shape=(6250000, 50), dtype=float32)"
          ]
        }
      ],
      "source": [
        "_, cost_history = train_model(model1,states, num_epochs=2000, lr=0.0001, decay=0.00001, _lambda=0)\n",
        "plt.plot(range(len(cost_history)), cost_history)\n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.title('Behaviour with epochs')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "magnitude_fx = 0\n",
        "magnitude_fy = 1\n",
        "x = np.linspace(-1, 1, num_points)\n",
        "y = np.linspace(-1, 1, num_points)\n",
        "fx = np.linspace(magnitude_fx,magnitude_fx, num_points)\n",
        "fy = np.linspace(magnitude_fy, magnitude_fy, num_points)\n",
        "\n",
        "grid_x, grid_y,grid_fx,grid_fy = np.meshgrid(x, y,fx,fy)\n",
        "new_states = np.array(list(zip(grid_x.reshape(-1), grid_y.reshape(-1),grid_fx.reshape(-1),grid_fy.reshape(-1))))\n",
        "\n",
        "plt.scatter(new_states[:,0], new_states[:,1])\n",
        "UV = model1(new_states)\n",
        "plt.scatter(new_states[:,0]+UV[:,0] , new_states[:,1] + UV[:,1], alpha=0.1)"
      ],
      "metadata": {
        "id": "LN_-2Vb5l539"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save_weights(\"pinn1.h5\")"
      ],
      "metadata": {
        "id": "Gr80Ge_9l7aI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aNdvct88oLgS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}